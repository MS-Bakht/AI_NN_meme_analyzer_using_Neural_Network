{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90daa48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchdata\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import os\n",
    "from skimage import color \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2857e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext\n",
    "#!pip install torchdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9115a71",
   "metadata": {},
   "source": [
    "### First setting up path of OS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "795dfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below code is for navigation while getting the path to the images folder and the names of all of the image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9e1b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = \"images\"    #Directory to the images folder (this code file is in the same folder)\n",
    "img_file_names=os.listdir(workspace) #Contains the names of all of image files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8ef1c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134a12e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_name</th>\n",
       "      <th>text_ocr</th>\n",
       "      <th>text_corrected</th>\n",
       "      <th>humour</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_1.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_2.jpeg</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>image_3.JPG</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>image_4.png</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>image_5.png</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>6987</td>\n",
       "      <td>image_6988.jpg</td>\n",
       "      <td>Tuesday is Mardi Gras Wednesday is Valentine's...</td>\n",
       "      <td>Tuesday is Mardi Gras Wednesday is Valentine's...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>6988</td>\n",
       "      <td>image_6989.jpg</td>\n",
       "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...</td>\n",
       "      <td>MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...</td>\n",
       "      <td>funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>6989</td>\n",
       "      <td>image_6990.png</td>\n",
       "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...</td>\n",
       "      <td>LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...</td>\n",
       "      <td>funny</td>\n",
       "      <td>general</td>\n",
       "      <td>slight</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6990</th>\n",
       "      <td>6990</td>\n",
       "      <td>image_6991.jpg</td>\n",
       "      <td>When I VERY have time is a fantasy No one has ...</td>\n",
       "      <td>When I have time is a fantasy. no one has time...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>very_positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6991</th>\n",
       "      <td>6991</td>\n",
       "      <td>image_6992.jpg</td>\n",
       "      <td>The starting point for every good idea is \"Wha...</td>\n",
       "      <td>The starting point for every good idea is \"Wha...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6992 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      image_name  \\\n",
       "0              0     image_1.jpg   \n",
       "1              1    image_2.jpeg   \n",
       "2              2     image_3.JPG   \n",
       "3              3     image_4.png   \n",
       "4              4     image_5.png   \n",
       "...          ...             ...   \n",
       "6987        6987  image_6988.jpg   \n",
       "6988        6988  image_6989.jpg   \n",
       "6989        6989  image_6990.png   \n",
       "6990        6990  image_6991.jpg   \n",
       "6991        6991  image_6992.jpg   \n",
       "\n",
       "                                               text_ocr  \\\n",
       "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1     The best of #10 YearChallenge! Completed in le...   \n",
       "2     Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3                 10 Year Challenge - Sweet Dee Edition   \n",
       "4     10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "...                                                 ...   \n",
       "6987  Tuesday is Mardi Gras Wednesday is Valentine's...   \n",
       "6988  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...   \n",
       "6989  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...   \n",
       "6990  When I VERY have time is a fantasy No one has ...   \n",
       "6991  The starting point for every good idea is \"Wha...   \n",
       "\n",
       "                                         text_corrected      humour  \\\n",
       "0     LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n",
       "1     The best of #10 YearChallenge! Completed in le...   not_funny   \n",
       "2     Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n",
       "3                 10 Year Challenge - Sweet Dee Edition  very_funny   \n",
       "4     10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n",
       "...                                                 ...         ...   \n",
       "6987  Tuesday is Mardi Gras Wednesday is Valentine's...  very_funny   \n",
       "6988  MUST WATCH MOVIES OF 2017 ITI Chennai memes MA...       funny   \n",
       "6989  LESS MORE TALKING PLANNING SODA JUNK FOOD COMP...       funny   \n",
       "6990  When I have time is a fantasy. no one has time...   not_funny   \n",
       "6991  The starting point for every good idea is \"Wha...   not_funny   \n",
       "\n",
       "              sarcasm       offensive      motivational overall_sentiment  \n",
       "0             general   not_offensive  not_motivational     very_positive  \n",
       "1             general   not_offensive      motivational     very_positive  \n",
       "2       not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3     twisted_meaning  very_offensive      motivational          positive  \n",
       "4        very_twisted  very_offensive  not_motivational           neutral  \n",
       "...               ...             ...               ...               ...  \n",
       "6987  twisted_meaning  very_offensive      motivational           neutral  \n",
       "6988  twisted_meaning   not_offensive  not_motivational           neutral  \n",
       "6989          general          slight  not_motivational          positive  \n",
       "6990  twisted_meaning   not_offensive      motivational     very_positive  \n",
       "6991    not_sarcastic   not_offensive      motivational          positive  \n",
       "\n",
       "[6992 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_file = pd.read_csv('labels.csv') #reading the provided data set\n",
    "dataset_file #displaying the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3635701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name        0\n",
       "text_corrected    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seperating the coloumns we need from the main dataset file which was provided to us\n",
    "selected_Col_p1 = dataset_file[[\"image_name\",\"text_corrected\"]]\n",
    "#Checking the null values\n",
    "selected_Col_p1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b515dcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[119, 4799, 6781, 6784, 6786]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#noting the indexes of the entries which have null text\n",
    "null_txt_list = selected_Col_p1[selected_Col_p1['text_corrected'].isnull()].index.tolist() \n",
    "null_txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The cell below will find all of the images names, which are greater than the size of 2000 because they will be outliars.\n",
    "#later on they will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb8aab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xade\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:819: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "#Noting images which are huge, outliars\n",
    "img_OLnames_list=[]\n",
    "#the below loop gives a list with the names \n",
    "for i in img_file_names:\n",
    "    image = imread(workspace+\"/\"+ i)\n",
    "    if image.shape[0] > 2000:\n",
    "        img_OLnames_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b47f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noting the indexes of the image outliars in the selected dataset\n",
    "str = []\n",
    "for i in img_OLnames_list:\n",
    "    str.append(selected_Col_p1[selected_Col_p1['image_name']==i].index.tolist())  #returns the index of the name\n",
    "\n",
    "#img_OLnames_list has the names of outliar images (ol means outliars)\n",
    "#ol_img_list will have their indexes \n",
    "\n",
    "ol_img_list=[]\n",
    "for i in str:\n",
    "    ol_img_list.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c6c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_index = ol_img_list + null_txt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4ad4aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before removing  6992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_name        0\n",
       "text_corrected    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Length before removing \", len(selected_Col_p1))\n",
    "selected_Col_p1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a9c627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after removing  6968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xade\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_name        0\n",
       "text_corrected    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing null values and outliars too\n",
    "selected_Col_p1.drop(labels=remove_index,axis=0, inplace=True)\n",
    "print(\"Length after removing \", len(selected_Col_p1)) \n",
    "selected_Col_p1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "28359552",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_Col_p1 = dataset_file[[\"overall_sentiment\"]]\n",
    "labels_Col_p1.drop(labels=remove_index,axis=0, inplace=True) #Dropping/removing the entries which are either outliars or have null valuyes as calculated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fab4f879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6968"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_Col_p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a624af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_Col_p1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58009799",
   "metadata": {},
   "source": [
    "# For Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18139ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xade\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:24: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "#Selecting only corrected text coloumn of  selected_Col_p1 in df_SCP1_tokenization to tokenize and get numbers for each word \n",
    "df_SCP1_tokenization = selected_Col_p1[\"text_corrected\"]\n",
    "\n",
    "def tokens(data):\n",
    "    for txt in data:\n",
    "        yield tokenizer(txt)\n",
    "\n",
    "vocab = build_vocab_from_iterator(tokens(df_SCP1_tokenization))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a393071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a neumeric array to store the numbers for every word \n",
    "neumeric_array = [] #to store word converted to numbers\n",
    "\n",
    "for sentence in df_SCP1_tokenization: #Selects a row (sentence, aka text_corrected) one by one\n",
    "    token = tokenizer(sentence) #tokenizes the sentences, that is breaks it into words. retuns a list with words in the sentence\n",
    "    #line below will convert word to number\n",
    "    neumeric_array.append(vocab(token)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9db9242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xade\\AppData\\Local\\Temp/ipykernel_15620/2356318947.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  neumeric_array = np.array(neumeric_array)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6968"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the list to numpy array \n",
    "neumeric_array = np.array(neumeric_array)\n",
    "len(neumeric_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0590dcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "#Finding the maximum length of the array which contains numeric words \n",
    "max_len=0\n",
    "for i in neumeric_array:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c011862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting and bringing all to the same size, by appending zeros\n",
    "for i in neumeric_array:\n",
    "    while (len(i) < max_len):\n",
    "        i.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2baeb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking if padding and equalizing the size worked\n",
    "#for i in neumeric_array:\n",
    "#    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bec7552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_neumeric_tensor = [] #converting the neumeric array into tensors\n",
    "for i in neumeric_array:\n",
    "    tensor_txt = torch.tensor(i)\n",
    "    text_neumeric_tensor.append(tensor_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "72aec1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lab=[]\n",
    "#Here, converting the labels to numbers for the model to understand\n",
    "#Giving very positive and positive 1, and so on\n",
    "for i in labels_Col_p1['overall_sentiment']:\n",
    "    try:\n",
    "        if (i == 'very_positive' or i == 'positive'):\n",
    "            i =  1\n",
    "        if (i == 'very_negative' or i == 'negative'):\n",
    "            i = 2\n",
    "        if (i == 'neutral'):\n",
    "            i = 0\n",
    "        final_lab.append(i)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a47aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor = []\n",
    "#converting labels from final_lab (containing 1,0,2) to tensors\n",
    "for Flabel in final_lab:\n",
    "    Flabel = torch.tensor(Flabel, dtype = torch.int)\n",
    "    label_tensor.append(Flabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "880ee912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view tensors of label\n",
    "#label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8b6f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view tensors of text neumerics\n",
    "#text_neumeric_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bf8b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_TENtext_train , x_TENtext_test , y_TENtext_train , y_TENtext_test = train_test_split(text_neumeric_tensor,label_tensor, test_size = 0.3, random_state = 60 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b9b84",
   "metadata": {},
   "source": [
    "# For Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "532968f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6973"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the names of the images with outliars values\n",
    "\n",
    "for i in img_OLnames_list:\n",
    "    img_file_names.remove(i) #removing the image from image list \n",
    "len(img_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77475c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now deleting the images which had no text in dataset\n",
    "nullvalues_df = dataset_file[[\"image_name\"]].loc[[ i for i in null_txt_list]]\n",
    "null_name_list=nullvalues_df.reset_index(drop=True)[\"image_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c1e7e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6968"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the names of the images with null values in text\n",
    "\n",
    "for i in null_name_list:\n",
    "    img_file_names.remove(i)\n",
    "len(img_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3512fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now creating tensors for image\n",
    "Img_tensor = []\n",
    "transform = transforms.ToTensor()\n",
    "for i in img_file_names:\n",
    "    image = imread(workspace+\"/\"+ i , as_gray=True)\n",
    "    image = resize(image, (250,250))\n",
    "    tensor = transform(image)\n",
    "    Img_tensor.append(tensor.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a08d27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62500"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_tensor_df = pd.DataFrame({'Img_Tensors':[*Img_tensor]})\n",
    "len(Img_tensor[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e27dbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_tensor_df.to_csv('Img_tensors_df.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "809b8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to read the saved image tensors\n",
    "img_tensor_df = pd.read_csv('Img_tensors_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12e272b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = img_tensor_df['Img_Tensors']\n",
    "x_img_train , x_img_test , y_img_train , y_img_test = train_test_split(Img_tensor,label_tensor , test_size= 0.3, random_state =60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b49a96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_img_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f9c31",
   "metadata": {},
   "source": [
    "# Neural Network (Part 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "019c3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Neural_Network_Model,self).__init__()\n",
    "\n",
    "        # Making layers for text first\n",
    "        self.linearText1 = nn.Linear(225, 200)\n",
    "        self.linearText2 = nn.Linear(200, 150)\n",
    "        self.linearText3 = nn.Linear(150, 130)\n",
    "        self.linearText4 = nn.Linear(130, 120)\n",
    "        self.linearText5 = nn.Linear(120, 100)\n",
    " \n",
    "        #then makeing picture layers\n",
    "        self.linearImg1 =  nn.Linear(250*250, 6000)\n",
    "        self.linearImg2 =  nn.Linear(6000, 4000)\n",
    "        self.linearImg3 =  nn.Linear(4000, 1000)\n",
    "        self.linearImg4 =  nn.Linear(1000, 900)\n",
    "        self.linearImg5 = nn.Linear(900, 700)\n",
    "\n",
    "        #Concetinating lyers\n",
    "        self.linearCat1  = nn.Linear(800, 500)\n",
    "        self.linearCat2  = nn.Linear(500, 350)\n",
    "        self.linearCat3  = nn.Linear(350, 300)\n",
    "        self.linearCat4  = nn.Linear(300, 250)\n",
    "        self.linearCat5  = nn.Linear(250, 100)\n",
    "        self.linearCat6  = nn.Linear(100, 3)\n",
    "\n",
    "        \n",
    "    def forward(self,ArgTxt,ArgImg):\n",
    "        sigTXT=torch.sigmoid(self.linearText1(ArgTxt))  \n",
    "        sigTXT= torch.sigmoid(self.linearText2(sigTXT)) \n",
    "        sigTXT= torch.sigmoid(self.linearText3(sigTXT)) \n",
    "        sigTXT= torch.sigmoid(self.linearText4(sigTXT)) \n",
    "        sigTXT = self.linearText5(sigTXT)\n",
    "        \n",
    "        sigIMG = torch.sigmoid(self.linearImg1(ArgImg))  \n",
    "        sigIMG = torch.sigmoid(self.linearImg2(sigIMG)) \n",
    "        sigIMG = torch.sigmoid(self.linearImg3(sigIMG)) \n",
    "        sigIMG = torch.sigmoid(self.linearImg4(sigIMG)) \n",
    "        sigIMG = self.linearImg5(sigIMG)\n",
    "        \n",
    "        txtNimg = torch.cat((sigTXT,sigIMG))\n",
    "\n",
    "        txtNimg = torch.sigmoid(self.linearCat1(txtNimg))  #Have to add more layers after joining to get a y shape instead of u shape\n",
    "        txtNimg = torch.sigmoid(self.linearCat2(txtNimg)) \n",
    "        txtNimg = torch.sigmoid(self.linearCat3(txtNimg)) \n",
    "        txtNimg = torch.sigmoid(self.linearCat4(txtNimg))\n",
    "        txtNimg = torch.sigmoid(self.linearCat5(txtNimg))\n",
    "         \n",
    "        Output_txtNimg = self.linearCat6(txtNimg)\n",
    "        return Output_txtNimg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bbd0ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Neural_Network_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c35a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd1530e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Accuracy:  75.0\n",
      "F1 score : 28.57142857142857\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  #times the loop will run over the dataset\n",
    "\n",
    "    # training\n",
    "    #for i in range(0,len(x_img_train)):\n",
    "    for i in range(0,20):\n",
    "\n",
    "        image = x_img_train[i].float()       # image tensor\n",
    "        text = x_TENtext_train[i].float()   #text tensor\n",
    "        label = y_img_train[i].type(torch.long)              #label tensor\n",
    "        pred = model(text, image)\n",
    "        loss = criterion(pred, label)  #calculate loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()               #update weights\n",
    "        \n",
    "\n",
    "    model_predictions = []\n",
    "    Ytest = []\n",
    "     #testing   \n",
    "    #for i in range(0,len(x_img_train)):\n",
    "    for i in range(0,20):\n",
    "        image = x_img_test[i].float()     # image tensor\n",
    "        text = x_TENtext_test[i].float()        #text tensor\n",
    "        label = y_img_test[i].type(torch.long)             #label tensor\n",
    "        pred = model(text, image)\n",
    "\n",
    "        model_predictions.append(int(torch.argmax(pred)))              \n",
    "        Ytest.append(y_img_test[i].cpu().detach().numpy())     # changing the tensor back to normal array\n",
    "\n",
    "    print(\"epoch\",epoch+1)\n",
    "    print(\"Accuracy: \",accuracy_score(Ytest,model_predictions)*100)\n",
    "    print('F1 score :',f1_score(Ytest,model_predictions,average = 'macro')*100)\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130ece1",
   "metadata": {},
   "source": [
    "# Part - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "91fa5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below seperating labels for humour, sarcasm, offensive and motivational, then removing the outliars and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "683ba633",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_humour = dataset_file[[\"humour\"]]\n",
    "labels_sarcasm = dataset_file[[\"sarcasm\"]]\n",
    "labels_offensive = dataset_file[[\"offensive\"]]\n",
    "labels_motivational = dataset_file[[\"motivational\"]]\n",
    "\n",
    "#Removing the index of outliars or the null values which were considered before\n",
    "\n",
    "labels_humour.drop(labels=remove_index,axis=0, inplace=True)\n",
    "labels_sarcasm.drop(labels=remove_index,axis=0, inplace=True)\n",
    "labels_offensive.drop(labels=remove_index,axis=0, inplace=True)\n",
    "labels_motivational.drop(labels=remove_index,axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b7152",
   "metadata": {},
   "source": [
    "## Humour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fb55d462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humour    \n",
       "funny         2442\n",
       "very_funny    2231\n",
       "not_funny     1645\n",
       "hilarious      650\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_humour.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d116d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lab_humour=[]\n",
    "#Here, converting the labels to numbers for the model to understand\n",
    "for i in labels_humour['humour']:\n",
    "    try:\n",
    "        if (i == 'not_funny'):\n",
    "            i =  0\n",
    "        else:\n",
    "            i = 1\n",
    "        \n",
    "        final_lab_humour.append(i)\n",
    "    except:\n",
    "        print(\"fail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8143dd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6968"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_lab_humour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9d72a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor_humour = []\n",
    "\n",
    "for Flabel in final_lab_humour:\n",
    "    Flabel = torch.tensor(Flabel, dtype = torch.int)\n",
    "    label_tensor_humour.append(Flabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c8b26",
   "metadata": {},
   "source": [
    "## Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8880097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sarcasm        \n",
       "general            3495\n",
       "twisted_meaning    1543\n",
       "not_sarcastic      1537\n",
       "very_twisted        393\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_sarcasm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cb5b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lab_sarcasm=[]\n",
    "#Here, converting the labels to numbers for the model to understand\n",
    "for i in labels_sarcasm['sarcasm']:\n",
    "    try:\n",
    "        if (i == 'not_sarcastic'):\n",
    "            i =  0\n",
    "        else:\n",
    "            i = 1\n",
    "        \n",
    "        final_lab_sarcasm.append(i)\n",
    "    except:\n",
    "        print(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d382f4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6968"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_lab_sarcasm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "03975f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor_sarcasm = []\n",
    "#converting labels from final_lab (containing 1,0,2) to tensors\n",
    "for Flabel in final_lab_sarcasm:\n",
    "    Flabel = torch.tensor(Flabel, dtype = torch.int)\n",
    "    label_tensor_sarcasm.append(Flabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bd1f00",
   "metadata": {},
   "source": [
    "## Offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c57b2f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offensive        \n",
       "not_offensive        2704\n",
       "slight               2583\n",
       "very_offensive       1460\n",
       "hateful_offensive     221\n",
       "dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_offensive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a08bcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lab_offensive=[]\n",
    "#Here, converting the labels to numbers for the model to understand\n",
    "for i in labels_offensive['offensive']:\n",
    "    try:\n",
    "        if (i == 'not_offensive'):\n",
    "            i =  0\n",
    "        else:\n",
    "            i = 1\n",
    "        \n",
    "        final_lab_offensive.append(i)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e03fa090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6968"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_lab_offensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ccb18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor_offensive = []\n",
    "#converting labels from final_lab (containing 1,0,2) to tensors\n",
    "for Flabel in final_lab_offensive:\n",
    "    Flabel = torch.tensor(Flabel, dtype = torch.int)\n",
    "    label_tensor_offensive.append(Flabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e88d5",
   "metadata": {},
   "source": [
    "## Motivational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a805134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "motivational    \n",
       "not_motivational    4510\n",
       "motivational        2458\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_motivational.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d6a419df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lab_motivational=[]\n",
    "#Here, converting the labels to numbers for the model to understand\n",
    "for i in labels_motivational['motivational']:\n",
    "    try:\n",
    "        if (i == 'not_motivational'):\n",
    "            i =  0\n",
    "        else:\n",
    "            i = 1\n",
    "        \n",
    "        final_lab_motivational.append(i)\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "847964ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6968"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_lab_motivational)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80a0e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor_motivational = []\n",
    "#converting labels from final_lab (containing 1,0,2) to tensors\n",
    "for Flabel in final_lab_motivational:\n",
    "    Flabel = torch.tensor(Flabel, dtype = torch.int)\n",
    "    label_tensor_motivational.append(Flabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d025a",
   "metadata": {},
   "source": [
    "# Neural Network (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6623ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network_Model_p2(nn.Module):\n",
    "    def _init_(self):\n",
    "        super(Neural_Network_Model_p2,self)._init_()\n",
    "\n",
    "        #making lyers for tezt \n",
    "        self.linearP2Text1 = nn.Linear(12933, 9000)\n",
    "        self.linearP2Text2 = nn.Linear(9000, 8000)\n",
    "        self.linearP2Text3 = nn.Linear(8000, 7000)\n",
    "        self.linearP2Text4 = nn.Linear(7000, 6000)\n",
    "        self.linearP2Text5 = nn.Linear(6000, 5000)\n",
    "        self.linearP2Text6 = nn.Linear(5000, 3500)\n",
    "        self.linearP2Text7 = nn.Linear(3500, 350)\n",
    "\n",
    "        #now making lyers for pictures \n",
    "        self.linearP2Img1 =  nn.Linear(250*250, 9000)    #250X250 because the images are resized\n",
    "        self.linearP2Img2 =  nn.Linear(9000, 8000)\n",
    "        self.linearP2Img3 =  nn.Linear(8000, 6000)\n",
    "        self.linearP2Img4 =  nn.Linear(6000, 5000)\n",
    "        self.linearP2Img5 =  nn.Linear(5000, 3500)\n",
    "        self.linearP2Img6 =  nn.Linear(3500, 500)\n",
    "        self.linearP2Img7 = nn.Linear(500, 350)\n",
    "\n",
    "        #comibined\n",
    "        self.linearP2Cat1  = nn.Linear(700, 600)     #350+350=700\n",
    "        self.linearP2Cat2  = nn.Linear(600, 550)\n",
    "        self.linearP2Cat3  = nn.Linear(550, 400)\n",
    "        self.linearP2Cat4  = nn.Linear(400, 350)\n",
    "        self.linearP2Cat5  = nn.Linear(350, 200)\n",
    "        self.linearP2Cat6  = nn.Linear(200, 100)\n",
    "        self.linearP2Cat7  = nn.Linear(100, 65)\n",
    "\n",
    "        #Humour\n",
    "        self.linearP2Hum1 = nn.Linear(65,40)\n",
    "        self.linearP2Hum2 = nn.Linear(40,30)\n",
    "        self.linearP2Hum3 = nn.Linear(30,20)\n",
    "        self.linearP2Hum4 = nn.Linear(20,10)\n",
    "        self.linearP2Hum5 = nn.Linear(10,4)     #there are 4 types of outputs in this coloume\n",
    "        \n",
    "        #sarcasm\n",
    "        self.linearP2Sar1 = nn.Linear(65,40)\n",
    "        self.linearP2Sar2 = nn.Linear(40,30)\n",
    "        self.linearP2Sar3 = nn.Linear(30,20)\n",
    "        self.linearP2Sar4 = nn.Linear(20,10)\n",
    "        self.linearP2Sar5 = nn.Linear(10,4)     #there are 4 types of outputs in this coloume\n",
    "\n",
    "        #offensive\n",
    "        self.linearP2Off1 = nn.Linear(65,40)\n",
    "        self.linearP2Off2 = nn.Linear(40,30)\n",
    "        self.linearP2Off3 = nn.Linear(30,20)\n",
    "        self.linearP2Off4 = nn.Linear(20,10)\n",
    "        self.linearP2Off5 = nn.Linear(10,4)    #there are 4 types of outputs in this coloume\n",
    "        \n",
    "        #Motivational\n",
    "        self.linearP2Moti1 = nn.Linear(65,40)\n",
    "        self.linearP2Moti2 = nn.Linear(40,10)\n",
    "        self.linearP2Moti3 = nn.Linear(40,10)\n",
    "        self.linearP2Moti4 = nn.Linear(40,10)\n",
    "        self.linearP2Moti5 = nn.Linear(10,2)      #there are only 2 types of outputs in motivational col\n",
    "\n",
    "        \n",
    "    def forward(self,P2ArgTxT,P2ArgImg):\n",
    "        P2sigTXT=torch.sigmoid(self.linearlinearP2Text1(P2ArgTxT))  \n",
    "        P2sigTXT= torch.sigmoid(self.linearlinearP2Text2(P2sigTXT)) \n",
    "        P2sigTXT= torch.sigmoid(self.linearlinearP2Text3(P2sigTXT)) \n",
    "        P2sigTXT= torch.sigmoid(self.linearlinearP2Text4(P2sigTXT)) \n",
    "        P2sigTXT= torch.sigmoid(self.linearlinearP2Text5(P2sigTXT))\n",
    "        P2sigTXT= torch.sigmoid(self.linearlinearP2Text6(P2sigTXT)) \n",
    "        P2sigTXT = self.linearP2Text7(P2sigTXT)        #Sending to the last layer of text which gives required outputs\n",
    "        \n",
    "        P2sigIMG = torch.sigmoid(self.linearP2Img1(P2ArgImg))  \n",
    "        P2sigIMG = torch.sigmoid(self.linearP2Img2(P2sigIMG)) \n",
    "        P2sigIMG = torch.sigmoid(self.linearP2Img3(P2sigIMG)) \n",
    "        P2sigIMG = torch.sigmoid(self.linearP2Img4(P2sigIMG)) \n",
    "        P2sigIMG = torch.sigmoid(self.linearP2Img5(P2sigIMG)) \n",
    "        P2sigIMG = torch.sigmoid(self.linearP2Img6(P2sigIMG)) \n",
    "        P2sigIMG = self.linearP2Img7(P2sigIMG)        #Sending to the last layer of text which gives required outputs\n",
    "        \n",
    "        P2txtNimg = torch.cat((P2sigTXT,P2sigIMG))\n",
    "\n",
    "        P2txtNimg = torch.sigmoid(self.linearP2Cat1(P2txtNimg))  #Have to add more layers after joining to get a y shape instead of u shape\n",
    "        P2txtNimg = torch.sigmoid(self.linearP2Cat2(P2txtNimg)) \n",
    "        P2txtNimg = torch.sigmoid(self.linearP2Cat3(P2txtNimg)) \n",
    "        P2txtNimg = torch.sigmoid(self.linearP2Cat4(P2txtNimg))\n",
    "        P2txtNimg = torch.sigmoid(self.linearP2Cat5(P2txtNimg))\n",
    "        P2txtNimg = torch.sigmoid(self.linearP2Cat6(P2txtNimg))\n",
    "        P2txtNimg = self.linearP2Cat7(P2txtNimg)        #Sending to the last layer of text which gives required outputs\n",
    "\n",
    "        #humour\n",
    "        p2h = torch.sigmoid(self.linearP2Hum1(P2txtNimg))\n",
    "        p2h = torch.sigmoid(self.linearP2Hum2(p2h))\n",
    "        p2h = torch.sigmoid(self.linearP2Hum3(p2h))\n",
    "        p2h = torch.sigmoid(self.linearP2Hum4(p2h))\n",
    "        p2_humour = self.linearP2Hum5(h)\n",
    "\n",
    "        \n",
    "        #sarcasm\n",
    "        p2s = torch.sigmoid(self.linearP2Sar1(P2txtNimg))\n",
    "        p2s = torch.sigmoid(self.linearP2Sar2(p2s))\n",
    "        p2s = torch.sigmoid(self.linearP2Sar3(p2s))\n",
    "        p2s = torch.sigmoid(self.linearP2Sar4(p2s))\n",
    "        p2_sarcasm = self.linearP2Sar5(p2s)\n",
    "\n",
    "        #offensive\n",
    "        p2o = torch.sigmoid(self.linearP2Off1(P2txtNimg))\n",
    "        p2o = torch.sigmoid(self.linearP2Off2(p2o))\n",
    "        p2o = torch.sigmoid(self.linearP2Off3(p2o))\n",
    "        p2o = torch.sigmoid(self.linearP2Off4(p2o))\n",
    "        p2_offensive = self.linearP2Off5(p2o)\n",
    "\n",
    "        #motivational\n",
    "        p2m = torch.sigmoid(self.linearP2Moti1(P2txtNimg))\n",
    "        p2m = torch.sigmoid(self.linearP2Moti2(p2m))\n",
    "        p2m = torch.sigmoid(self.linearP2Moti3(p2m))\n",
    "        p2m = torch.sigmoid(self.linearP2Moti4(p2m))\n",
    "        p2_motivational = self.linearP2Moti5(p2m)\n",
    "\n",
    "\n",
    "\n",
    "        return p2_humour,p2_sarcasm,p2_offensive,p2_motivational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f9483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3714cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
